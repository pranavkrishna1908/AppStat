---
title: "Final Report"
output: html_document
date: "2023-04-22"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## US Presidential Elections

The election of the President of the United States of America is a closely watched world event which has significant implications for domestic and international affairs not just in America, but all over the world. In the past, linear models with some specially constructed variables were used to predict the results at the state level. In this report, we will investigate this practice by first making a linear model, and then a mixed model and compare their fit and predictions.

## Description of the data

The data is the percentage of the Statewide vote which was for the Democratic candidate from the years 1948 to 1992. This will be our response variable, instead of the nationwide election results.

Among the predictor variables, we have year and state. The other variables we have are as follows - 
* `year`

* `state`

* nationwide variables `n1,...,n4`

    1. support for the Democratic candidate in the September exit poll

    2. (presidential approval in the Jully exit poll) $\times$ `Inc`

    3. (presidential approval in the Jully exit poll) $\times$ `Presinc`

    4. (2nd quarter GDP growth) $\times$ `Inc`

* statewide variables `s1,...,s9`

    1. Democratic vote share in the state in the last election (as deviation from the corresponding national vote)
    
    2. Democratic vote share in the state vote two elections ago (again, as a deviation from national)
    
    3. home state of the presidential candidate
    
    4. home state of the vice-presidential candidate
    
    5. Democratic majority in the state legislature
    
    6. (state economic growth in the past year) $\times$ `Inc`
    
    7. state ideology measurement
    
    8. ideological compatibility with candidates for each state
    
    9. proportion of Catholics in 1960 compared to U.S. average (1960 had a Catholic presidential candidate)
    
* regional/sub-regional variables `r1,...,r6`
   
    1. South indicator
   
    2. (South indicator in 1964) $\times$ (-1)
   
    3. (deep South indicator in 1964) $\times$ (-1)
   
    4. New England indicator in 1964
   
    5. New England indicator in 1972
   
    6. (West in 1976) 

where `Inc` is 1 or -1 depending on whether the incumbent President is a Democrat or Republican, `Presinc` equals `Inc` if the incumbent President is running for a re-election and is 0 otherwise. All variables are positively signed towards Democrats, so e.g. `s3` is 1 for the home state of the Democratic cadidate and -1 for the home state of the Republican candidate. The year 1964 was strange because the Democratic candidate Lyndon B. Johnson was able to completely dominate the elections also in the South, with the exception of the "deep South" states. There are other regional variables to adjust for known and expected outliers instead of removing them.

Lastly, we create another variable called Region which signifies the geographical region for the states. Assuming the states are numbered in alphabetical order, the reions are constructed as follows - 

Northeast: 7 8 19 20 21 29 30 32 38 39 45 48,

South: 1 4 9 10 17 18 24 33 36 40 42 43 46,

Midwest: 13 14 15 16 22 23 25 27 34 35 41 49 and 

West: 2 3 5 6 11 12 26 28 31 37 44 47 50.

## Linear model

The first linear model we investigate is  

$$
D_{vote} = C_1 + \mathbf{1}_{\text{Year}} \cdot C_{\text{Year}} + \mathbf{1}_{\text{State}} \cdot C_{\text{State}} + \Sigma_{i = 1}^4 C_{n_i} \cdot n_i + \Sigma_{i = 1}^9 C_{s_i} \cdot s_i + \Sigma_{i = 1}^6 C_{r_i} \cdot r_i 
$$
```{r linear, include = FALSE}
library(readr)
library(lme4)
library(tidyverse)
X4_US_elections <- read_table("E:/EPFL/AppStat/AppStat/Data/4_US_elections.txt")
Election_data = X4_US_elections
Election_data$Region = rep(0, nrow(Election_data))
Northeast = c(7 ,8 ,19, 20, 21, 29, 30, 32, 38, 39, 45, 48)
South = c(1, 4, 9, 10, 17, 18, 24, 33, 36, 40, 42, 43, 46)
Midwest = c(13 ,14 ,15 ,16 ,22 ,23 ,25 ,27 ,34 ,35 ,41 ,49)
West = c(2 ,3 ,5 ,6 ,11 ,12 ,26 ,28 ,31 ,37 ,44 ,47 ,50)
Election_data$Region[which(Election_data$state %in% West)] = 'West'
Election_data$Region[which(Election_data$state %in% Midwest)] = 'Midwest'
Election_data$Region[which(Election_data$state %in% South)] = 'South'
Election_data$Region[which(Election_data$state %in% Northeast)] = 'Northeast'
Election_data$constant = NULL
Election_data = drop_na(Election_data)
Originaldata = Election_data
Election_data$state = as.factor(Election_data$state)
Election_data$year = as.factor(Election_data$year)
linear_model = lm(Dvote~.-evotes - Region , data = Election_data)
linear_model2 = lm(Dvote~.-evotes - Region - year - s7 , data = Election_data)
```
We recognise that this model does not have all coefficients estimable. For example, we see that the 'measure of state ideology' variable is equivalent to adding states as the state ideology is not allowed to change in time. 

A more interesting observation is that the nationwide variables will change every year and we know that we already have year as a factor variable. Thus, the coefficients for the nationwide variables are also inestimable.

Thus, we have a cleaner linear model which does not have Year(so as to allow it to predict in a wider range of situations) and s7( it is equivalent to having the state). Thus, the linear model we have is as follows -

$$
D_{vote} = C_1 +  \mathbf{1}_{\text{State}} \cdot C_{\text{State}}  + \Sigma_{i = 1}^4 C_{n_i} \cdot n_i + \Sigma_{i = 1, i \neq 7}^9 C_{s_i} \cdot s_i + \Sigma_{i = 1}^6 C_{r_i} \cdot r_i 
$$

## Diagnostics for the linear model

We observe that the linear model may not be the most appropriate because the response is bounded between zero and 1. While the diagnostic plots are more or less appropriate, we expect some dependence between the results within a year, region and state. On investigating the residuals grouped by region and year, we see significant dependence in the residuals. 

```{r echo=FALSE}
tempdata = Election_data
tempdata$group = paste(tempdata$Region , tempdata$year)
ggplot(data = tempdata, aes(y = linear_model2$residuals, col =  group)) + 
  geom_boxplot() + 
  ggtitle("Figure 1: Residuals grouped by Region and Year for the linear model") + 
  theme(plot.caption = element_text(size = 18))+
  ylab('Residuals')
```

Figure 1 raises serious questions about homoskedasticity in the model, as the lengths of the box plots vary significantly. Furthermore, we see that   the residuals for South and West are worse compared to northeast and Midwest. This motivates a mixed effects model for the data.

## Mixed Effects Model

We observe that the data generating process is such that the observations within each year are correlated. Similarly, residuals suggest that there is correlation within Regions for each year. Thus, we allow a nested effects model such that the response is the proportion of Democratic votes. The first level of random effects is the Year grouping and in the dependence structure, we allow a grouping at the Region level.

$$
Y_{\text{y,r}} = X_{\text{yr}} \beta + Z_{\text{y,r}} b_y + Z_{\text{yr}} b_{\text{yr}} +\epsilon_{\text{yr}}
$$
In this model, $Y_{\text{y,r}}$ contains the individual observations for each state, $X_{\text{yr}}$ is the matrix of fixed effects, namely State, the national variables, the state variables and the regional variables. Again, we choose to drop s7, the measure of state ideology, because it is collinear with the state and does not change in time. The $Z_{\text{y,r}}$ indicates the first level of random effects, the Year, and the $Z_{\text{yr}}$ indicates the second level, Regions within the year.

```{r pressure, echo=FALSE, include=FALSE}
mixed_model = lmer(Dvote~. -evotes  - year -Region -s7 + (1|year/Region) , data=Election_data)
```

On making a similar grouping of the residuals as figure 1 for this model, we see some improvement in the residuals. All boxplots pass through the zero line, but we still see significant variation in the engths of the boxplots. 

```{r echo = FALSE}
ggplot(data = tempdata, aes(y = residuals(mixed_model), col =  group)) + 
  geom_boxplot() + 
  ggtitle("Figure 2: Residuals grouped by Region and Year for the mixed model") + 
  theme(plot.caption = element_text(size = 18))+
  ylab('Residuals')
```

 We observe that the model fits the data for all regions except the south. This is surprising because we have three regional variables dedicated to capturing this phenomenon. We try to check the effectiveness of the model without some regional variables by running a Bootstrap test.
```{r include = FALSE}
ggplot(data = tempdata, aes(y = residuals(mixed_model), x =  group, col = group)) + 
  geom_point() + 
  ggtitle("Figure 2: Residuals grouped by Region and Year for the mixed model") + 
  theme(plot.caption = element_text(size = 18))+
  ylab('Residuals')
#ibrary(janitor) tabyl(Election_data[abs(residuals(mixed_model1)) > 0.05, ], Region)
```

## Variable Importance for the regional variables

We conduct a parametric BootStrap to test the importance of the variables and find out that none of the variables are individually important, as the p values are more than 0.5 for all of them. Next,considering that we were able to adequately model the data for all regions except South, we remove the regional variables that are not related to it. We get a p value of 0.762, whch suggests that we can remove these variables. Next, when we take the bolder step of removing all regional variables and observe that the p value is still above 0.5, meaning that we can drop all the regional variables. 

When we compare the BIC for these model, we see a significant drop for each of the steps and decide to not discard any of the regional variables in the final model. Thus, we stay with the model mentioned in the beginning. Thus, we decide to keep all the regional covariates in the model. This is also because we do not want to degrade the already bad performance of the model for the Southern region.

Next, we tried to simplify the dependence structure by running a bootstrap test for the Random effect of Year. We got a large p value. Furthermore, on investigating the random coefficients for Year, we observed that the coefficients were all the same and the estimated variance is zero. Thus, we decided to drop this level of randomness from the model.

Thus, the final model we choose to have a model which contains only one level of random effects for each region and year. The final mixed model we have is as follows -
$$
Y_{\text{y,r}} = X_{\text{yr}} \beta + Z_{\text{yr}} b_{\text{yr}} +\epsilon_{\text{yr}}
$$

```{r include=FALSE}
mixed_model_fin = lmer(Dvote~. -evotes  - year -Region -s7   + (1|year:Region) , data=Election_data,REML=T)

```

## Diagnostics for the Mixed model

Recall that for the Mixed model, we expect the 'Random Coefficients' to be Gaussian. We investigate this by making a QQplot and observe that this does indeed hold true. We also checked the model fit by investigating the residuals grouped by region and year. We again mention that the model was able to adequately fit the data, except for the South, where the model made errors in both directions. Lastly, we make the corresponding plot for the final model

```{r echo = FALSE}
#plot(fitted(mixed_model_fin), resid(mixed_model_fin))
ggplot(data = tempdata, aes(y = residuals(mixed_model_fin), x =  group, col = group)) + 
  geom_point() + 
  ggtitle("Figure 3: Residuals grouped by Region and Year for the Final Mixed Model") + 
  theme(plot.caption = element_text(size = 18))+
  ylab('Residuals')
#qqnorm(ranef(mixed_model_fin)$'year:Region'[,1])
```

## Comparison of the mixed model and the linear model

We observe in Figure 3 that the residuals are centered at zero, which is definitely an improvement over the linear model, but we do not believe that it is a significant improvement. Recall that an interaction term in the linear model between Year and Region would have a similar effect on the residuals of the linear model. In our opinion, the introduction of the mixed model, even though theoretically more appropriate, does not lead to a significant improvement in the fit of the model. We had intended to remove heteroskedasticity, which still exists in the model. Thus, deffeating the purpose of mixed modelling. 








